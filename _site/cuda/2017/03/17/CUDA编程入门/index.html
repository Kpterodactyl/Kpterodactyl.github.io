<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="google-site-verification" content="xBT4GhYoi5qRD5tr338pgPM5OWHHIDR6mNg1a3euekI" />
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="每个胜利背后都有许多尝试">
    <meta name="keywords"  content="">
    <meta name="theme-color" content="#000000">
    
    <title>CUDA编程基础知识+示例 - 阿坤的博客 | KUN Blog</title>

    <!-- Web App Manifest -->
    <link rel="manifest" href="/pwa/manifest.json">

    <!-- Favicon -->
    <link rel="shortcut icon" href="/img/favicon.ico">
    
    <!-- Canonical URL -->
    <link rel="canonical" href="http://localhost:5001/cuda/2017/03/17/CUDA%E7%BC%96%E7%A8%8B%E5%85%A5%E9%97%A8/">

    <!-- Bootstrap Core CSS -->
    <link rel="stylesheet" href="/css/bootstrap.min.css">

    <!-- Custom CSS -->
    <link rel="stylesheet" href="/css/hux-blog.min.css">

    <!-- Pygments Github CSS -->
    <link rel="stylesheet" href="/css/syntax.css">

    <!-- Custom Fonts -->
    <!-- <link href="http://maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css" rel="stylesheet" type="text/css"> -->
    <!-- Hux change font-awesome CDN to qiniu -->
    <link href="//cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css">


    <!-- Hux Delete, sad but pending in China
    <link href='http://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
    <link href='http://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800' rel='stylesheet' type='text/
    css'>
    -->


    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

    <!-- ga & ba script hoook -->
    <script></script>
</head>


<!-- hack iOS CSS :active style -->
<body ontouchstart="">

    <!-- Navigation -->
<nav class="navbar navbar-default navbar-custom navbar-fixed-top">
    <div class="container-fluid">
        <!-- Brand and toggle get grouped for better mobile display -->
        <div class="navbar-header page-scroll">
            <button type="button" class="navbar-toggle">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="/">Memory</a>
        </div>

        <!-- Collect the nav links, forms, and other content for toggling -->
        <div id="huxblog_navbar">
            <div class="navbar-collapse">
                <ul class="nav navbar-nav navbar-right">
                    <li>
                        <a href="/">Home</a>
                    </li>
                    
                    <li>
                        <a href="/about/">About</a>
                    </li>
                    
                    <li>
                        <a href="/tags/">Tags</a>
                    </li>
                    
                </ul>
            </div>
        </div>
        <!-- /.navbar-collapse -->
    </div>
    <!-- /.container -->
</nav>
<script>
    // Drop Bootstarp low-performance Navbar
    // Use customize navbar with high-quality material design animation
    // in high-perf jank-free CSS3 implementation
    var $body   = document.body;
    var $toggle = document.querySelector('.navbar-toggle');
    var $navbar = document.querySelector('#huxblog_navbar');
    var $collapse = document.querySelector('.navbar-collapse');

    var __HuxNav__ = {
        close: function(){
            $navbar.className = " ";
            // wait until animation end.
            setTimeout(function(){
                // prevent frequently toggle
                if($navbar.className.indexOf('in') < 0) {
                    $collapse.style.height = "0px"
                }
            },400)
        },
        open: function(){
            $collapse.style.height = "auto"
            $navbar.className += " in";
        }
    }

    // Bind Event
    $toggle.addEventListener('click', function(e){
        if ($navbar.className.indexOf('in') > 0) {
            __HuxNav__.close()
        }else{
            __HuxNav__.open()
        }
    })

    /**
     * Since Fastclick is used to delegate 'touchstart' globally
     * to hack 300ms delay in iOS by performing a fake 'click',
     * Using 'e.stopPropagation' to stop 'touchstart' event from 
     * $toggle/$collapse will break global delegation.
     * 
     * Instead, we use a 'e.target' filter to prevent handler
     * added to document close HuxNav.  
     *
     * Also, we use 'click' instead of 'touchstart' as compromise
     */
    document.addEventListener('click', function(e){
        if(e.target == $toggle) return;
        if(e.target.className == 'icon-bar') return;
        __HuxNav__.close();
    })
</script>


    <!-- Image to hack wechat -->
<!-- <img src="/img/icon_wechat.png" width="0" height="0"> -->
<!-- <img src="/img/post-bg-js-module.jpg" width="0" height="0"> -->

<!-- Post Header -->
<style type="text/css">
    header.intro-header{
        position: relative;
        background-image: url('/img/post-bg-js-module.jpg')
    }

    
</style>
<header class="intro-header" >
    <div class="header-mask"></div>
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <div class="post-heading">
                    <div class="tags">
                        
                        <a class="tag" href="/tags/#CUDA" title="CUDA">CUDA</a>
                        
                        <a class="tag" href="/tags/#GPU" title="GPU">GPU</a>
                        
                    </div>
                    <h1>CUDA编程基础知识+示例</h1>
                    
                    
                    <h2 class="subheading"></h2>
                    
                    <span class="meta">Posted by Memory on March 17, 2017</span>
                </div>
            </div>
        </div>
    </div>
</header>

<!-- Post Content -->
<article>
    <div class="container">
        <div class="row">

    <!-- Post Container -->
            <div class="
                col-lg-8 col-lg-offset-2
                col-md-10 col-md-offset-1
                post-container">

				<p>一个CUDA程序一般分为两部分</p>

<ul>
  <li>
    <p>Host 运行在CPU端，逻辑判断密集型</p>
  </li>
  <li>
    <p>Device 运行在GPU端，计算密集型</p>
  </li>
</ul>

<p><strong>内存分配</strong>：无论是CPU端的主存还是GPU端的显存，都必须通过CUDA在主机端进行统一分配</p>

<p><strong>CUDA编程模型：</strong>
GPU与CPU交互通过PCIE总线进行互联，CUDA的线程结构是网格-线程块-线程（是CUDA程序的最小执行单元）三级结构。
<img src="http://i.imgur.com/h43llVa.png" alt="" /></p>

<h2 id="cuda函数声明">CUDA函数声明</h2>
<p>Kernel函数（入口函数）在CPU上调用在GPU上执行，GPU在执行kernel函数的时候面向线程。 
<img src="http://i.imgur.com/jdGG8hl.png" alt="" /></p>

<p>CUDA中的kernel函数是一个可以在CUDA程序中被独立并行执行的一个过程。</p>
<h1 id="cuda-api语法">CUDA API语法</h1>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">__global__</span> <span class="n">void</span> <span class="no">Compute</span><span class="p">(</span><span class="n">int</span> <span class="o">*</span><span class="n">gpudata</span><span class="p">)</span> <span class="p">{</span> <span class="p">.</span><span class="nf">.</span><span class="p">.</span><span class="nf">.</span><span class="p">.</span><span class="nf">.</span><span class="o">.</span><span class="p">}</span></code></pre></figure>

<p>调用方式</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="no">Compute</span><span class="o">&lt;&lt;&lt;</span><span class="n">m</span><span class="p">,</span><span class="n">n</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">)</span></code></pre></figure>

<p>其中«&lt; »&gt;是运算符，用来传递要调用的kernel函数的执行参数，m代表每个Grid中的Block数量，n代表每个Block中的Thread数量，«&lt; »&gt;也包含每个Block能够分配的额外shared memory大小，隐藏默认为1。   a,b是函数调用的实参。</p>

<p>每个	Grid分为N个Block，每个Block分为M个Thread，则每个线程的序号为 N*M+ThreadID.x。</p>
<h1 id="索引计算方法">索引计算方法</h1>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="n">int</span> <span class="n">tid</span> <span class="o">=</span> <span class="n">threadIdx</span><span class="p">.</span><span class="nf">x</span> <span class="o">+</span> <span class="n">blockIdx</span><span class="p">.</span><span class="nf">x</span> <span class="o">*</span> <span class="n">blockDim</span><span class="p">.</span><span class="nf">x</span><span class="p">;</span></code></pre></figure>

<ul>
  <li>
    <p>threadIdx.x表示当前线程所在线程块中某行的索引，</p>
  </li>
  <li>
    <p>blockIdx.x表示线程块索引，</p>
  </li>
  <li>
    <p>blockDim.x表示每个线程块中的线程数量</p>
  </li>
  <li>
    <p>gridDim.x表示当前线程格中线程块的数量</p>
  </li>
</ul>

<p>开始学习CUDA编程啦，觉得通过具体的例子来解释CUDA编程的关键点会好很多吧。这是我开始学习的第一个例子，求立方和，以下是完整的代码，具体的解释在各行中有注释，在便于我回忆的同时希望对大家会有帮助。<br />
通过以下形式启动核函数：</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"> <span class="n">add</span><span class="o">&lt;&lt;&lt;</span><span class="mi">5</span><span class="p">,</span><span class="mi">1</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">param1</span><span class="p">,</span><span class="n">param2</span><span class="p">.</span><span class="nf">.</span><span class="p">.</span><span class="nf">.</span><span class="o">.</span><span class="p">)</span>  </code></pre></figure>

<p>可以认为运行时将创建核函数的5个副本，并以并行的方式来运行</p>

<figure class="highlight"><pre><code class="language-ruby" data-lang="ruby"><span class="c1">#include &lt;stdio.h&gt;</span>
<span class="c1">#include &lt;assert.h&gt;</span>
<span class="c1">#define DATA_SIZE 1048576</span>

<span class="n">int</span> <span class="n">data</span><span class="p">[</span><span class="no">DATA_SIZE</span><span class="p">];</span>

<span class="n">void</span> <span class="no">GenerateNumbers</span><span class="p">(</span><span class="n">int</span> <span class="o">*</span><span class="n">number</span><span class="p">,</span> <span class="n">int</span> <span class="n">size</span><span class="p">)</span>
<span class="p">{</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">size</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
        <span class="nb">srand</span><span class="p">(</span><span class="mi">3</span><span class="p">);</span>
        <span class="n">number</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="nb">rand</span><span class="p">()</span> <span class="o">%</span> <span class="mi">10</span><span class="p">;</span>
    <span class="p">}</span>

<span class="p">}</span>
<span class="sr">//</span> <span class="no">Simple</span> <span class="n">utility</span> <span class="n">function</span> <span class="n">to</span> <span class="n">check</span> <span class="k">for</span> <span class="no">CUDA</span> <span class="n">runtime</span> <span class="n">errors</span>
<span class="n">void</span> <span class="n">checkCUDAError</span><span class="p">(</span><span class="n">const</span> <span class="n">char</span> <span class="o">*</span><span class="n">msg</span><span class="p">);</span>

<span class="sr">//</span> <span class="no">Part</span> <span class="mi">3</span> <span class="n">of</span> <span class="mi">5</span><span class="p">:</span> <span class="n">implement</span> <span class="n">the</span> <span class="n">kernel</span>
<span class="n">__global__</span> <span class="n">void</span> <span class="n">myFirstKernel</span><span class="p">(</span><span class="n">int</span> <span class="o">*</span><span class="n">num</span><span class="p">,</span> <span class="n">int</span> <span class="o">*</span><span class="n">result</span><span class="p">)</span>
<span class="p">{</span>
    <span class="n">int</span> <span class="n">sum</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
       <span class="sr">//</span><span class="err">计算位于这个索引处的数据，</span><span class="n">dim3</span><span class="err">为二维数组，要通过</span><span class="n">x</span><span class="err">和</span><span class="n">y</span><span class="err">来对应数据位置，这样才可以给每个线程块制定运算的数据</span>
       <span class="sr">//</span><span class="err">将</span><span class="n">threadIdx</span><span class="o">/</span><span class="no">BlockIdx</span><span class="err">映射到像素位置</span>
       <span class="n">int</span> <span class="n">x</span> <span class="o">=</span> <span class="n">threadIdx</span><span class="p">.</span><span class="nf">x</span> <span class="o">+</span> <span class="n">blockIdx</span><span class="p">.</span><span class="nf">x</span> <span class="o">*</span> <span class="n">blockDim</span><span class="p">.</span><span class="nf">x</span><span class="p">;</span>
       <span class="n">int</span> <span class="n">y</span> <span class="o">=</span> <span class="n">threadIdx</span><span class="p">.</span><span class="nf">y</span> <span class="o">+</span> <span class="n">blockIdx</span><span class="p">.</span><span class="nf">y</span> <span class="o">*</span> <span class="n">blockDim</span><span class="p">.</span><span class="nf">y</span><span class="p">;</span>
       <span class="sr">//</span><span class="n">blockIdx</span><span class="p">.</span><span class="nf">y</span><span class="o">*</span><span class="n">blockDim</span><span class="p">.</span><span class="nf">y</span><span class="err">代表每一横行的线程数</span>
       <span class="n">int</span> <span class="n">tid</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">y</span> <span class="o">*</span> <span class="n">blockDim</span><span class="p">.</span><span class="nf">x</span> <span class="o">*</span> <span class="n">gridDim</span><span class="p">.</span><span class="nf">x</span><span class="p">;</span>
        <span class="k">for</span> <span class="p">(</span><span class="n">tid</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">tid</span> <span class="o">&lt;</span> <span class="no">DATA_SIZE</span><span class="p">;</span> <span class="n">tid</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
            <span class="n">sum</span> <span class="o">+=</span> <span class="n">num</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span> <span class="o">*</span> <span class="n">num</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span> <span class="o">*</span> <span class="n">num</span><span class="p">[</span><span class="n">tid</span><span class="p">];</span>
        <span class="p">}</span>
        <span class="o">*</span><span class="n">result</span> <span class="o">=</span> <span class="n">sum</span><span class="p">;</span>
<span class="p">}</span>

<span class="n">int</span> <span class="n">main</span><span class="p">(</span> <span class="p">)</span> 

<span class="p">{</span>    
    <span class="sr">//</span><span class="n">pointer</span> <span class="k">for</span> <span class="n">host</span> <span class="n">memory</span>
    <span class="n">int</span> <span class="o">*</span><span class="n">h_a</span><span class="p">;</span> 
    <span class="sr">//</span><span class="n">pointer</span> <span class="k">for</span> <span class="n">device</span> <span class="n">memory</span><span class="p">(</span><span class="no">GPU</span><span class="p">)</span>
    <span class="n">int</span> <span class="o">*</span><span class="n">d_a</span><span class="p">;</span>
    <span class="sr">//</span><span class="no">GPU</span><span class="err">上计算结果定义并分配内存</span>
    <span class="n">int</span> <span class="o">*</span><span class="n">result</span><span class="p">;</span>
    <span class="n">cudaMalloc</span><span class="p">((</span><span class="n">void</span><span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">result</span><span class="p">,</span> <span class="n">sizeof</span><span class="p">(</span><span class="n">int</span><span class="p">));</span>

    <span class="sr">//</span> <span class="no">Part</span> <span class="mi">1</span> <span class="n">of</span> <span class="mi">5</span><span class="p">:</span> <span class="n">allocate</span> <span class="n">host</span> <span class="n">and</span> <span class="n">device</span> <span class="n">memory</span>
    <span class="n">size_t</span> <span class="n">memSize</span> <span class="o">=</span>  <span class="n">sizeof</span><span class="p">(</span><span class="n">int</span><span class="p">)</span><span class="o">*</span> <span class="no">DATA_SIZE</span><span class="p">;</span>
    <span class="n">h_a</span> <span class="o">=</span> <span class="p">(</span><span class="n">int</span> <span class="o">*</span><span class="p">)</span> <span class="n">malloc</span><span class="p">(</span><span class="n">memSize</span><span class="p">);</span>
    <span class="sr">//</span><span class="n">cudaMalloc</span><span class="p">()</span><span class="err">第一个参数是一个指针，用于保存新分配内存地址的变量，第二个是内存大小</span>
    <span class="n">cudaMalloc</span><span class="p">((</span><span class="n">void</span><span class="o">**</span><span class="p">)</span><span class="o">&amp;</span><span class="n">d_a</span><span class="p">,</span><span class="n">memSize</span><span class="p">);</span>
    <span class="sr">//</span><span class="err">调用生成随机数的函数，生成随机数的位置在</span><span class="n">host</span><span class="err">端</span><span class="o">*</span><span class="n">h_a</span><span class="err">，在这里要注意分配内存的顺序</span>
    <span class="sr">//</span><span class="err">该函数中的参数</span><span class="n">h_a</span><span class="err">一定要先分配内存</span>
    <span class="no">GenerateNumbers</span><span class="p">(</span><span class="n">h_a</span><span class="p">,</span><span class="no">DATA_SIZE</span><span class="p">);</span>
    <span class="sr">//</span><span class="n">cudaMemcpy</span><span class="err">（目的，源，要拷贝的大小，方向）</span>
    <span class="sr">//</span><span class="err">将</span><span class="n">h_a</span><span class="err">中的生成的随机数传输给</span><span class="n">d_a</span><span class="err">，源是</span><span class="n">host</span>
    <span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">d_a</span><span class="p">,</span><span class="n">h_a</span><span class="p">,</span><span class="n">sizeof</span><span class="p">(</span><span class="n">int</span><span class="p">)</span><span class="o">*</span> <span class="no">DATA_SIZE</span><span class="p">,</span> <span class="n">cudaMemcpyHostToDevice</span><span class="p">);</span>

    <span class="sr">//</span> <span class="no">Part</span> <span class="mi">2</span> <span class="n">of</span> <span class="mi">5</span><span class="p">:</span> <span class="n">configure</span> <span class="n">and</span> <span class="n">launch</span> <span class="n">kernel</span>
    <span class="sr">//</span><span class="err">通过</span><span class="n">dim3</span> <span class="err">声明一个二维格，其实是三维但是</span><span class="no">CUDA</span><span class="err">运行时会自动把第三维制定为</span><span class="mi">1</span>
    <span class="n">dim3</span> <span class="n">dimGrid</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">4</span><span class="p">);</span>
    <span class="n">dim3</span> <span class="n">dimBlock</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span><span class="mi">16</span><span class="p">);</span>
    <span class="sr">//m</span><span class="n">yFirstKernel</span><span class="err">参数即要传给核函数的值</span>
    <span class="n">myFirstKernel</span><span class="o">&lt;&lt;&lt;</span> <span class="n">dimGrid</span><span class="p">,</span><span class="n">dimBlock</span> <span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">d_a</span><span class="p">,</span><span class="n">result</span><span class="p">);</span>

    <span class="sr">//</span> <span class="n">block</span> <span class="k">until</span> <span class="n">the</span> <span class="n">device</span> <span class="n">has</span> <span class="n">completed</span>
    <span class="n">cudaThreadSynchronize</span><span class="p">();</span>

    <span class="sr">//</span><span class="nb">printf</span><span class="p">(</span><span class="s2">"GPUsum: %d</span><span class="se">\n</span><span class="s2">"</span><span class="p">,</span> <span class="o">*</span><span class="n">result</span><span class="p">);</span>
    <span class="sr">//</span> <span class="n">check</span> <span class="k">if</span> <span class="n">kernel</span> <span class="n">execution</span> <span class="n">generated</span> <span class="n">an</span> <span class="n">error</span>
    <span class="n">checkCUDAError</span><span class="p">(</span><span class="s2">"kernel execution"</span><span class="p">);</span>

    <span class="n">int</span> <span class="no">SumResult</span><span class="p">;</span>

    <span class="sr">//</span> <span class="no">Part</span> <span class="mi">4</span> <span class="n">of</span> <span class="mi">5</span><span class="p">:</span> <span class="n">device</span> <span class="n">to</span> <span class="n">host</span> <span class="n">copy</span>
    <span class="n">cudaMemcpy</span><span class="p">(</span><span class="o">&amp;</span><span class="no">SumResult</span><span class="p">,</span><span class="n">result</span><span class="p">,</span><span class="n">sizeof</span><span class="p">(</span><span class="n">int</span><span class="p">),</span><span class="n">cudaMemcpyDeviceToHost</span><span class="p">);</span>

    <span class="sr">//</span> <span class="no">Check</span> <span class="k">for</span> <span class="n">any</span> <span class="no">CUDA</span> <span class="n">errors</span>
    <span class="n">checkCUDAError</span><span class="p">(</span><span class="s2">"cudaMemcpy"</span><span class="p">);</span>

    <span class="sr">//</span> <span class="no">Part</span> <span class="mi">5</span> <span class="n">of</span> <span class="mi">5</span><span class="p">:</span> <span class="n">verify</span> <span class="n">the</span> <span class="n">data</span> <span class="n">returned</span> <span class="n">to</span> <span class="n">the</span> <span class="n">host</span> <span class="n">is</span> <span class="n">correct</span>
    <span class="sr">//</span><span class="err">常会用到</span><span class="n">assert</span><span class="p">()</span><span class="err">断言判断计算是否正确</span>
    <span class="nb">printf</span><span class="p">(</span><span class="s2">"Sum Result: %d </span><span class="se">\n</span><span class="s2">"</span><span class="p">,</span> <span class="no">SumResult</span><span class="p">);</span>

    <span class="sr">//</span> <span class="n">free</span> <span class="n">device</span> <span class="n">memory</span>
    <span class="n">cudaFree</span><span class="p">(</span><span class="n">d_a</span><span class="p">);</span>
    <span class="n">cudaFree</span><span class="p">(</span><span class="n">result</span><span class="p">);</span>

    <span class="sr">//</span> <span class="n">free</span> <span class="n">host</span> <span class="n">memory</span>
    <span class="n">free</span><span class="p">(</span><span class="n">h_a</span><span class="p">);</span>

    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>

        <span class="p">}</span>
<span class="n">void</span> <span class="n">checkCUDAError</span><span class="p">(</span><span class="n">const</span> <span class="n">char</span> <span class="o">*</span><span class="n">msg</span><span class="p">)</span>
<span class="p">{</span>
    <span class="n">cudaError_t</span> <span class="n">err</span> <span class="o">=</span> <span class="n">cudaGetLastError</span><span class="p">();</span>
    <span class="k">if</span><span class="p">(</span> <span class="n">cudaSuccess</span> <span class="o">!=</span> <span class="n">err</span><span class="p">)</span> 
    <span class="p">{</span>
        <span class="n">fprintf</span><span class="p">(</span><span class="n">stderr</span><span class="p">,</span> <span class="s2">"Cuda error: %s: %s.</span><span class="se">\n</span><span class="s2">"</span><span class="p">,</span> <span class="n">msg</span><span class="p">,</span> <span class="n">cudaGetErrorString</span><span class="p">(</span> <span class="n">err</span><span class="p">)</span> <span class="p">);</span>
        <span class="nb">exit</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">);</span>
    <span class="p">}</span>                         
<span class="p">}</span></code></pre></figure>



                <hr style="visibility: hidden;">

                


                <ul class="pager">
                    
                    <li class="previous">
                        <a href="/cuda/2017/03/14/CUDA-GDB%E4%BD%BF%E7%94%A8/" data-toggle="tooltip" data-placement="top" title="How to use cuda-gdb debug">
                        Previous<br>
                        <span>How to use cuda-gdb debug</span>
                        </a>
                    </li>
                    
                    
                    <li class="next">
                        <a href="/2017/03/31/Docker%E5%9F%BA%E7%A1%80%E6%8C%87%E4%BB%A4%E5%8F%8ADockerfile/" data-toggle="tooltip" data-placement="top" title="Docker基础知识">
                        Next<br>
                        <span>Docker基础知识</span>
                        </a>
                    </li>
                    
                </ul>


                

                

            </div>  

    <!-- Side Catalog Container -->
        

    <!-- Sidebar Container -->
            <div class="
                col-lg-8 col-lg-offset-2
                col-md-10 col-md-offset-1
                sidebar-container">

                <!-- Friends Blog -->
                
            </div>
        </div>
    </div>
</article>









<!-- async load function -->
<script>
    function async(u, c) {
      var d = document, t = 'script',
          o = d.createElement(t),
          s = d.getElementsByTagName(t)[0];
      o.src = u;
      if (c) { o.addEventListener('load', function (e) { c(null, e); }, false); }
      s.parentNode.insertBefore(o, s);
    }
</script>
<!-- anchor-js, Doc:http://bryanbraun.github.io/anchorjs/ -->
<script>
    async("//cdnjs.cloudflare.com/ajax/libs/anchor-js/1.1.1/anchor.min.js",function(){
        anchors.options = {
          visible: 'always',
          placement: 'right',
          icon: '#'
        };
        anchors.add().remove('.intro-header h1').remove('.subheading').remove('.sidebar-container h5');
    })
</script>
<style>
    /* place left on bigger screen */
    @media all and (min-width: 800px) {
        .anchorjs-link{
            position: absolute;
            left: -0.75em;
            font-size: 1.1em;
            margin-top : -0.1em;
        }
    }
</style>


    <!-- Footer -->
<footer>
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <ul class="list-inline text-center">
                    
                    <!-- add jianshu add target = "_blank" to <a> by BY -->
                    
                    

                    <!-- add Weibo, Zhihu by Hux, add target = "_blank" to <a> by Hux -->
                    
                    


                    
                    
                    
                </ul>
                <p class="copyright text-muted">
                    Copyright &copy; Memory 2017
                    <br>
                    Theme by <a href="http://huangxuan.me">Hux</a> |
                    <iframe
                        style="margin-left: 2px; margin-bottom:-5px;"
                        frameborder="0" scrolling="0" width="100px" height="20px"
                        src="https://ghbtns.com/github-btn.html?user=huxpro&repo=huxpro.github.io&type=star&count=true" >
                    </iframe>
                </p>
            </div>
        </div>
    </div>
</footer>

<!-- jQuery -->
<script src="/js/jquery.min.js "></script>

<!-- Bootstrap Core JavaScript -->
<script src="/js/bootstrap.min.js "></script>

<!-- Custom Theme JavaScript -->
<script src="/js/hux-blog.min.js "></script>

<!-- Service Worker -->

<script type="text/javascript">
    if(navigator.serviceWorker){
        // For security reasons, a service worker can only control the pages that are in the same directory level or below it. That's why we put sw.js at ROOT level.
        navigator.serviceWorker
            .register('/sw.js')
            .then((registration) => {console.log('Service Worker Registered. ', registration)})
            .catch((error) => {console.log('ServiceWorker registration failed: ', error)})
    }
</script>



<!-- async load function -->
<script>
    function async(u, c) {
      var d = document, t = 'script',
          o = d.createElement(t),
          s = d.getElementsByTagName(t)[0];
      o.src = u;
      if (c) { o.addEventListener('load', function (e) { c(null, e); }, false); }
      s.parentNode.insertBefore(o, s);
    }
</script>

<!-- 
     Because of the native support for backtick-style fenced code blocks 
     right within the Markdown is landed in Github Pages, 
     From V1.6, There is no need for Highlight.js, 
     so Huxblog drops it officially.

     - https://github.com/blog/2100-github-pages-now-faster-and-simpler-with-jekyll-3-0  
     - https://help.github.com/articles/creating-and-highlighting-code-blocks/ 
     - https://github.com/jneen/rouge/wiki/list-of-supported-languages-and-lexers   
-->
<!--
    <script>
        async("http://cdn.bootcss.com/highlight.js/8.6/highlight.min.js", function(){
            hljs.initHighlightingOnLoad();
        })
    </script>
    <link href="http://cdn.bootcss.com/highlight.js/8.6/styles/github.min.css" rel="stylesheet">
-->


<!-- jquery.tagcloud.js -->
<script>
    // only load tagcloud.js in tag.html
    if($('#tag_cloud').length !== 0){
        async('/js/jquery.tagcloud.js',function(){
            $.fn.tagcloud.defaults = {
                //size: {start: 1, end: 1, unit: 'em'},
                color: {start: '#bbbbee', end: '#0085a1'},
            };
            $('#tag_cloud a').tagcloud();
        })
    }
</script>

<!--fastClick.js -->
<script>
    async("//cdnjs.cloudflare.com/ajax/libs/fastclick/1.0.6/fastclick.min.js", function(){
        var $nav = document.querySelector("nav");
        if($nav) FastClick.attach($nav);
    })
</script>


<!-- Google Analytics -->



<!-- Baidu Tongji -->

<script>
    // dynamic User by Hux
    var _baId = 'b50bf2b12b5338a1845e33832976fd68';

    // Originial
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "//hm.baidu.com/hm.js?" + _baId;
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
</script>




<!-- Side Catalog -->





<!-- Image to hack wechat -->
<img src="/img/my_icon_wechat.png" width="0" height="0" />
<!-- Migrate from head to bottom, no longer block render and still work -->

</body>

</html>
