---
layout: post
title:  "在云计算和集群环境中使用CUDA"
date:   2017-04-13 09:20:23 +0800
header-img: img/post-bg-universe.jpg
author:     Memory
categories: CUDA
tags:
    - CUDA
    - GPU
    - MPI
---

使用MPI使CUDA扩展至使用上千个节点，NVIDIA的GPUDirect技术加速了MPI发送（**MPI_send**)和（**MPI_Receive**)等关键操作。通过MPI个GPUDirect的使用，利用这些API创建云计算在计算集群上运行的程序。     
**MPI**消息传递接口，定义了并行计算的拓扑结构，用来将一组进场组织成一个MPI会话，**MPI会话的尺寸在整个程序执行生命周期中是固定不变的**。
MPI中所有的并行都是显示的，编程者需要负责制定正确的并行度，并实现MPI程序构建中的并行算法。

## **MPI通信器** ##

通信器是一个分布式对象，用于完成集中式和点对点的通信，集中式通信是指与制定通信组中所有处理器有关的MPI函数，点对点通信用于单个MPI进程之间的传递。   
**点对点通信** 完成两个不同MPI之间的通信，其中一个进程进行发送操作，另一个进程进行对应的读操作。MPI保证所有的消息都可以完整无误的送达对端。  MPI_Send()和MPI——Recv()通常采用**暂停**方式处理两个MPI进程直接的消息传递。 暂停意味着发送消息的进程将一直等待信息被完整准确发送后再返回；而接受消息的进程也将一直等待消息被完整正确的接收后再返回。     
默认情况下，在调用**MPI_init()** 后，MPI会立刻创建**MPI_COMM_WORLD**通信器。 MPI_COMM_WORLD包含了程序中所有的MPI进程。  
一个MPI程序可以创建多个相互独立的通信器，用来独立处理一组任务相关的消息，或从一组进程到另一组相关进程之间的通信。


## **MPI进程号** ##

在通信器内，每个线程在其初始化后，系统都会分配一个唯一的整数识别码。 进程号也称为“任务ID”，用于条件判断操作，用来控制MPI线程的执行。
MPI程序通常选用进程号为0的进程作为主进程，通过主进程来控制其它进程号大于0的进程。
MPI程序结构图通常如下图所示：
![](http://i.imgur.com/EtVWKpN.png)


## **主从模式** ##

MPI的通用设计模式是主从模式，进程号为0的被定义为主进程，该进程用来管理其它所有进程的活动。下面是构建主从模式的MPI代码

{% highlight ruby %}
MPI_Comm_size(MPI_COMM_WORLD.&numtasks);
MPI_Comm_rank(MPI_COMM_WORLD.&rank);
if(rank == 0) {
   //此处为主进程代码
}else {
   //此次为从进程代码
}
{% endhighlight %}  
## **MPI通信器** ##

通信器是一个分布式对象，用于完成集中式和点对点的通信，集中式通信是指与制定通信组中所有处理器有关的MPI函数，点对点通信用于单个MPI进程之间的传递。   
**点对点通信** 完成两个不同MPI之间的通信，其中一个进程进行发送操作，另一个进程进行对应的读操作。MPI保证所有的消息都可以完整无误的送达对端。  MPI_Send()和MPI——Recv()通常采用**暂停**方式处理两个MPI进程直接的消息传递。 暂停意味着发送消息的进程将一直等待信息被完整准确发送后再返回；而接受消息的进程也将一直等待消息被完整正确的接收后再返回。     
默认情况下，在调用**MPI_init()** 后，MPI会立刻创建**MPI_COMM_WORLD**通信器。 MPI_COMM_WORLD包含了程序中所有的MPI进程。  
一个MPI程序可以创建多个相互独立的通信器，用来独立处理一组任务相关的消息，或从一组进程到另一组相关进程之间的通信。


## **MPI进程号** ##

在通信器内，每个线程在其初始化后，系统都会分配一个唯一的整数识别码。 进程号也称为“任务ID”，用于条件判断操作，用来控制MPI线程的执行。
MPI程序通常选用进程号为0的进程作为主进程，通过主进程来控制其它进程号大于0的进程。
MPI程序结构图通常如下图所示：
![](http://i.imgur.com/EtVWKpN.png)


## **主从模式** ##

MPI的通用设计模式是主从模式，进程号为0的被定义为主进程，该进程用来管理其它所有进程的活动。下面是构建主从模式的MPI代码

{% highlight ruby %}
MPI_Comm_size(MPI_COMM_WORLD.&numtasks);
MPI_Comm_rank(MPI_COMM_WORLD.&rank);
if(rank == 0) {
   //此处为主进程代码
}else {
   //此次为从进程代码
}
{% endhighlight %}  
## **MPI通信器** ##

通信器是一个分布式对象，用于完成集中式和点对点的通信，集中式通信是指与制定通信组中所有处理器有关的MPI函数，点对点通信用于单个MPI进程之间的传递。   
**点对点通信** 完成两个不同MPI之间的通信，其中一个进程进行发送操作，另一个进程进行对应的读操作。MPI保证所有的消息都可以完整无误的送达对端。  MPI_Send()和MPI——Recv()通常采用**暂停**方式处理两个MPI进程直接的消息传递。 暂停意味着发送消息的进程将一直等待信息被完整准确发送后再返回；而接受消息的进程也将一直等待消息被完整正确的接收后再返回。     
默认情况下，在调用**MPI_init()** 后，MPI会立刻创建**MPI_COMM_WORLD**通信器。 MPI_COMM_WORLD包含了程序中所有的MPI进程。  
一个MPI程序可以创建多个相互独立的通信器，用来独立处理一组任务相关的消息，或从一组进程到另一组相关进程之间的通信。


## **MPI进程号** ##

在通信器内，每个线程在其初始化后，系统都会分配一个唯一的整数识别码。 进程号也称为“任务ID”，用于条件判断操作，用来控制MPI线程的执行。
MPI程序通常选用进程号为0的进程作为主进程，通过主进程来控制其它进程号大于0的进程。
MPI程序结构图通常如下图所示：
![](http://i.imgur.com/EtVWKpN.png)


## **主从模式** ##

MPI的通用设计模式是主从模式，进程号为0的被定义为主进程，该进程用来管理其它所有进程的活动。下面是构建主从模式的MPI代码

{% highlight ruby %}
MPI_Comm_size(MPI_COMM_WORLD.&numtasks);
MPI_Comm_rank(MPI_COMM_WORLD.&rank);
if(rank == 0) {
   //此处为主进程代码
}else {
   //此次为从进程代码
}
{% endhighlight %}  


