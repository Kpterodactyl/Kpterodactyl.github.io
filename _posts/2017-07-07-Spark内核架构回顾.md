

Spark注重建立良好的生态系统，不仅支持多种外部文件存储系统，而且提供了多种运行模式。部署在单台机器上时，既可以用本地（Local）模式运行，也可以使用伪分布式模式来运行；当以分布式集群部署是，可以根据自己集群的实际情况选择独立（standalone）运行模式来运行、YARN运行模式、还是Mesos运行模式。     
Spark虽然支持多种运行模式，但Spark应用程序的运行架构基本由三部分组成，包括   
1. SparkContext（驱动程序）   
2. ClusterManager（集群资源管理程序）   
3. Executor（任务执行进程）   
 ![](http://i.imgur.com/RHzn6FF.png)
## 各部分功能详解 ##   
**Driver**是专门用来提交Spark程序的机器：这台机器一般一定和Spark Cluster在同样的网络环境中（Driver和Executor通信频繁），且其配置和普通的Worker一致。  Application（各种依赖的外部资源，例如*.so File)，使用`spark-submit`去运行各种程序（可以配置运行时的各种参数，例如memory cores...),实例生产环境下写Shell脚本自动化配置和提交程序。    
Dirver的核心是**SparkContext**其作用为：创建DAGScheduler、TaskScheduler、SchedulerBackend，在实例化的过程中Register当前程序给Master，Master接收注册，如果没有问题，Master会为当前程序分配AppId并分配计算资源。
一般情况下，当通过action触发Job时SparkContex会通过DAGScheduler来把Job中的RDD构成的DAG划分为不同的Stage，每个Stage内部是一系列业务逻辑相同但处理数据不同的Tasks，构成了TaskSet。 TaskScheduler和SchedulerBackend负责具体Task的运行（遵循数据本地性）。    
**Spark Cluster** 中**Master**：接收用户提交的程序并发送指令给Worker为当前程序分配计算资源，每个Worker所在节点默认为当前程序分配一个Executor，在Executor中通过线程池并发执行。      
Master通知Worker按照要求启动Exectuor。   
**Worker Node**中Worker进程，通过一个Proxy为ExecutorRunner的对象实例来远程启动ExecutorBackend进行； **ExecutorBacken**进程里面有Executor，实际在工作时候会通过TaskRunner来封装Task，然后从ThrePool中获取一条线程执行Task，执行完后线程被回收复用。 最后一个StageTask称为ResultTask，产生Job结果，其它前面的Stage中的Task都是ShuffleMapTask，为下一阶段的Stage做数据准备，相当于MapReduce中的mapper。   
整个Spark程序的运行，就是DAGScheduler把Job划分成不同的Stage，提交TaskSet给TaskScheduler，进而提交给Executor执行（符合数据本地性），每个Task会计算RDD中的一个Partition，基于Partition来具体执行我们定义的一系列同一个Stage内部的函数，依此类推直到整个程序完成。
![](http://i.imgur.com/Molmr7u.png)







    
