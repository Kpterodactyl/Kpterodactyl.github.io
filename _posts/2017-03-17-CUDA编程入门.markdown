---
layout: post
title:  CUDA编程基础知识+示例
date:   2017-03-17 18:53:23 +0800
author:     Memory
header-img: img/post-bg-js-module.jpg
categories: CUDA
tags:
    - CUDA
    - GPU
---
一个CUDA程序一般分为两部分


- Host 运行在CPU端，逻辑判断密集型


- Device 运行在GPU端，计算密集型


**内存分配**：无论是CPU端的主存还是GPU端的显存，都必须通过CUDA在主机端进行统一分配


**CUDA编程模型：**
GPU与CPU交互通过PCIE总线进行互联，CUDA的线程结构是网格-线程块-线程（是CUDA程序的最小执行单元）三级结构。
![](http://i.imgur.com/h43llVa.png)

## CUDA函数声明 ##
Kernel函数（入口函数）在CPU上调用在GPU上执行，GPU在执行kernel函数的时候面向线程。 
![](http://i.imgur.com/jdGG8hl.png)  

CUDA中的kernel函数是一个可以在CUDA程序中被独立并行执行的一个过程。
# CUDA API语法 #
{% highlight ruby %}
__global__ void Compute(int *gpudata) { .......}
{% endhighlight %}  
调用方式    
{% highlight ruby %}
Compute<<<m,n>>>(a,b)
{% endhighlight %}  
其中<<< >>>是运算符，用来传递要调用的kernel函数的执行参数，m代表每个Grid中的Block数量，n代表每个Block中的Thread数量，<<< >>>也包含每个Block能够分配的额外shared memory大小，隐藏默认为1。   a,b是函数调用的实参。   

每个	Grid分为N个Block，每个Block分为M个Thread，则每个线程的序号为 N*M+ThreadID.x。 
# 索引计算方法 #
{% highlight ruby %}
int tid = threadIdx.x + blockIdx.x * blockDim.x;
{% endhighlight %}    
threadIdx.x表示当前线程所在线程块中某行的索引，blockIdx.x表示线程块索引，blockDim.x表示每个线程块中的线程数量。gridDim.x表示当前线程格中线程块的数量


开始学习CUDA编程啦，觉得通过具体的例子来解释CUDA编程的关键点会好很多吧。这是我开始学习的第一个例子，求立方和，以下是完整的代码，具体的解释在各行中有注释，在便于我回忆的同时希望对大家会有帮助。  
通过以下形式启动核函数：
   {% highlight ruby %} add<<<5,1>>>(param1,param2.....)  {% endhighlight %}
可以认为运行时将创建核函数的5个副本，并以并行的方式来运行

{% highlight ruby %}
#include <stdio.h>
#include <assert.h>
#define DATA_SIZE 1048576

int data[DATA_SIZE];

void GenerateNumbers(int *number, int size)
{
    for (int i = 0; i < size; i++) {
        srand(3);
        number[i] = rand() % 10;
    }

}
// Simple utility function to check for CUDA runtime errors
void checkCUDAError(const char *msg);

// Part 3 of 5: implement the kernel
__global__ void myFirstKernel(int *num, int *result)
{
    int sum = 0;
       //计算位于这个索引处的数据，dim3为二维数组，要通过x和y来对应数据位置，这样才可以给每个线程块制定运算的数据
       //将threadIdx/BlockIdx映射到像素位置
       int x = threadIdx.x + blockIdx.x * blockDim.x;
       int y = threadIdx.y + blockIdx.y * blockDim.y;
       //blockIdx.y*blockDim.y代表每一横行的线程数
       int tid = x + y * blockDim.x * gridDim.x;
        for (tid = 0; tid < DATA_SIZE; tid++) {
            sum += num[tid] * num[tid] * num[tid];
        }
        *result = sum;
}

int main( ) 

{    
    //pointer for host memory
    int *h_a; 
    //pointer for device memory(GPU)
    int *d_a;
    //GPU上计算结果定义并分配内存
    int *result;
    cudaMalloc((void**)&result, sizeof(int));

    // Part 1 of 5: allocate host and device memory
    size_t memSize =  sizeof(int)* DATA_SIZE;
    h_a = (int *) malloc(memSize);
    //cudaMalloc()第一个参数是一个指针，用于保存新分配内存地址的变量，第二个是内存大小
    cudaMalloc((void**)&d_a,memSize);
    //调用生成随机数的函数，生成随机数的位置在host端*h_a，在这里要注意分配内存的顺序
    //该函数中的参数h_a一定要先分配内存
    GenerateNumbers(h_a,DATA_SIZE);
    //cudaMemcpy（目的，源，要拷贝的大小，方向）
    //将h_a中的生成的随机数传输给d_a，源是host
    cudaMemcpy(d_a,h_a,sizeof(int)* DATA_SIZE, cudaMemcpyHostToDevice);

    // Part 2 of 5: configure and launch kernel
    //通过dim3 声明一个二维格，其实是三维但是CUDA运行时会自动把第三维制定为1
    dim3 dimGrid(2,4);
    dim3 dimBlock(4,16);
    //myFirstKernel参数即要传给核函数的值
    myFirstKernel<<< dimGrid,dimBlock >>>(d_a,result);

    // block until the device has completed
    cudaThreadSynchronize();

    //printf("GPUsum: %d\n", *result);
    // check if kernel execution generated an error
    checkCUDAError("kernel execution");

    int SumResult;

    // Part 4 of 5: device to host copy
    cudaMemcpy(&SumResult,result,sizeof(int),cudaMemcpyDeviceToHost);

    // Check for any CUDA errors
    checkCUDAError("cudaMemcpy");

    // Part 5 of 5: verify the data returned to the host is correct
    //常会用到assert()断言判断计算是否正确
    printf("Sum Result: %d \n", SumResult);

    // free device memory
    cudaFree(d_a);
    cudaFree(result);

    // free host memory
    free(h_a);

    return 0;

        }
void checkCUDAError(const char *msg)
{
    cudaError_t err = cudaGetLastError();
    if( cudaSuccess != err) 
    {
        fprintf(stderr, "Cuda error: %s: %s.\n", msg, cudaGetErrorString( err) );
        exit(-1);
    }                         
}

{% endhighlight %}

